# Databricks IoT Connector Configuration
# Production-ready DMZ deployment configuration

# ZeroBus Connection Settings
zerobus:
  workspace_host: "https://your-workspace.cloud.databricks.com"
  zerobus_endpoint: "your-endpoint.zerobus.region.cloud.databricks.com"

  # OAuth2 Service Principal Authentication
  auth:
    client_id: "${DATABRICKS_CLIENT_ID}"  # Read from environment variable
    client_secret: "${DATABRICKS_CLIENT_SECRET}"  # Read from environment variable
    token_endpoint: "https://your-workspace.cloud.databricks.com/oidc/v1/token"

  # Target Unity Catalog destination
  target:
    catalog: "iot_data"
    schema: "bronze"
    table: "sensor_events"

  # Connection settings
  connection:
    timeout_seconds: 30
    max_retries: 3
    retry_backoff_multiplier: 2
    health_check_interval_seconds: 60

# Data Source Configurations
sources:
  # OPC-UA Sources
  - name: "plant_floor_opcua"
    protocol: "opcua"
    enabled: true
    endpoint: "opc.tcp://192.168.1.100:4840"  # Customer's OPC-UA server

    # OPC-UA specific settings
    opcua:
      security_policy: "Basic256Sha256"  # None, Basic128Rsa15, Basic256, Basic256Sha256
      security_mode: "SignAndEncrypt"  # None, Sign, SignAndEncrypt
      certificate_path: "certs/opcua/client_cert.der"
      private_key_path: "certs/opcua/client_key.pem"
      server_certificate_path: "certs/opcua/server_cert.der"

      # Authentication
      username: "${OPCUA_USERNAME}"
      password: "${OPCUA_PASSWORD}"

      # Subscription settings
      subscription:
        publishing_interval_ms: 1000
        max_notifications_per_publish: 100
        priority: 0

      # Node monitoring
      nodes:
        - node_id: "ns=2;s=Temperature"
          sampling_interval_ms: 1000
        - node_id: "ns=2;s=Pressure"
          sampling_interval_ms: 1000
        - browse_path: "0:Root/0:Objects/2:ProcessArea"
          recursive: true
          depth: 2

  # MQTT Sources
  - name: "sensor_network_mqtt"
    protocol: "mqtt"
    enabled: true
    endpoint: "mqtt://192.168.1.200:1883"  # Customer's MQTT broker

    # MQTT specific settings
    mqtt:
      # TLS/SSL Configuration
      tls:
        enabled: true
        ca_cert_path: "certs/mqtt/ca.crt"
        client_cert_path: "certs/mqtt/client.crt"
        client_key_path: "certs/mqtt/client.key"
        verify_mode: "CERT_REQUIRED"  # CERT_NONE, CERT_OPTIONAL, CERT_REQUIRED
        tls_version: "TLSv1.2"  # TLSv1.2, TLSv1.3

      # Authentication
      username: "${MQTT_USERNAME}"
      password: "${MQTT_PASSWORD}"

      # Connection settings
      client_id: "databricks_iot_connector"
      clean_session: false
      keepalive_seconds: 60
      reconnect_on_failure: true

      # Subscriptions
      topics:
        - topic: "sensors/temperature/#"
          qos: 1
        - topic: "sensors/pressure/#"
          qos: 1
        - topic: "alerts/+/critical"
          qos: 2

  # Modbus Sources
  - name: "plc_modbus_tcp"
    protocol: "modbus"
    enabled: true
    endpoint: "modbus+tcp://192.168.1.150:502"  # Customer's Modbus TCP device

    # Modbus specific settings
    modbus:
      # Connection type: tcp or rtu
      connection_type: "tcp"
      slave_id: 1

      # Polling configuration
      poll_interval_seconds: 1
      timeout_seconds: 3

      # Register mappings
      registers:
        - address: 40001
          count: 10
          register_type: "holding"  # holding, input, coil, discrete
          data_type: "float32"  # int16, uint16, int32, uint32, float32, float64
          byte_order: "big"  # big, little
          word_order: "big"  # big, little
          scale_factor: 0.1
          offset: 0
          name: "temperature"

        - address: 40011
          count: 1
          register_type: "holding"
          data_type: "uint16"
          name: "pressure"

  # Modbus RTU (Serial)
  - name: "field_device_modbus_rtu"
    protocol: "modbus"
    enabled: false
    endpoint: "modbus+rtu:///dev/ttyUSB0"  # Serial port

    modbus:
      connection_type: "rtu"
      slave_id: 2

      # Serial port settings
      serial:
        baudrate: 9600
        bytesize: 8
        parity: "N"  # N (None), E (Even), O (Odd)
        stopbits: 1
        timeout_seconds: 1

      poll_interval_seconds: 2

      registers:
        - address: 30001
          count: 5
          register_type: "input"
          data_type: "int16"

# Backpressure Management
backpressure:
  enabled: true

  # In-memory queue settings
  memory_queue:
    max_size: 10000  # Maximum records in memory
    drop_policy: "oldest"  # oldest, newest, reject_new
    warning_threshold: 0.8  # Warn when 80% full

  # Disk spooling (when memory queue is full)
  disk_spool:
    enabled: true
    path: "spool"
    max_size_mb: 1000
    max_files: 100
    compression: true  # Compress spooled records
    encryption: true  # Encrypt spooled data at rest
    encryption_key_path: "certs/spool_encryption.key"

# Data Processing
processing:
  # Batching
  batch:
    max_size: 100  # Records per batch
    max_wait_seconds: 5  # Maximum time to wait before sending partial batch

  # Transformation
  transform:
    enabled: true
    add_metadata: true  # Add connector metadata to each record
    timestamp_format: "microseconds"  # microseconds, milliseconds, iso8601

  # Data validation
  validation:
    enabled: true
    drop_invalid: false  # If true, drop invalid records; if false, send to DLQ
    required_fields: ["event_time", "source_name"]

  # Dead Letter Queue
  dead_letter_queue:
    enabled: true
    path: "spool/dlq"
    max_size_mb: 100

# Resilience & Reliability
resilience:
  # Connection retry
  reconnect:
    enabled: true
    initial_delay_seconds: 1
    max_delay_seconds: 300
    backoff_multiplier: 2
    max_attempts: 0  # 0 = infinite retries

  # Circuit breaker
  circuit_breaker:
    enabled: true
    failure_threshold: 5  # Open circuit after N consecutive failures
    success_threshold: 2  # Close circuit after N consecutive successes
    timeout_seconds: 60  # Time to wait before trying again

  # Health checks
  health_check:
    enabled: true
    interval_seconds: 30
    endpoint: "http://0.0.0.0:8080/health"  # Expose health check endpoint

# Monitoring & Observability
monitoring:
  # Metrics
  metrics:
    enabled: true
    export_interval_seconds: 60

    # Prometheus exporter
    prometheus:
      enabled: true
      port: 9090
      path: "/metrics"

    # Metrics to track
    tracked_metrics:
      - records_read_total
      - records_written_total
      - records_failed_total
      - batch_size_bytes
      - batch_latency_seconds
      - connection_status
      - queue_depth
      - spool_size_bytes

  # Logging
  logging:
    level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
    format: "json"  # json, text
    output: "file"  # file, stdout, both
    file_path: "logs/connector.log"

    # Log rotation
    rotation:
      max_size_mb: 100
      max_files: 10
      compress: true

    # Structured logging fields
    include_fields:
      - timestamp
      - level
      - source
      - message
      - trace_id
      - error_details

  # Distributed tracing
  tracing:
    enabled: true
    service_name: "databricks-iot-connector"

    # OpenTelemetry exporter
    otlp:
      enabled: true
      endpoint: "http://localhost:4318"  # OTLP/HTTP endpoint

  # Alerting
  alerts:
    enabled: true

    # Alert rules
    rules:
      - name: "high_failure_rate"
        condition: "failure_rate > 0.1"
        window_seconds: 300
        severity: "critical"

      - name: "queue_near_full"
        condition: "queue_depth > 0.9 * max_queue_size"
        severity: "warning"

      - name: "connection_down"
        condition: "connection_status == 0"
        duration_seconds: 60
        severity: "critical"

    # Alert destinations
    destinations:
      - type: "email"
        enabled: false
        smtp_host: "smtp.company.com"
        smtp_port: 587
        from: "iot-connector@company.com"
        to: ["ops@company.com"]

      - type: "webhook"
        enabled: false
        url: "https://hooks.company.com/alerts"
        method: "POST"

# Security
security:
  # Certificate management
  certificates:
    auto_rotation: true
    rotation_days_before_expiry: 30
    validation:
      verify_hostname: true
      verify_chain: true
      check_revocation: true

  # Secrets management
  secrets:
    provider: "env"  # env, vault, azure_keyvault, aws_secrets_manager

    # HashiCorp Vault (if provider: vault)
    vault:
      address: "https://vault.company.com"
      token_path: "/etc/vault/token"
      mount_point: "secret"
      path: "iot-connector"

  # Network security
  network:
    # Firewall rules (documentation only)
    required_outbound:
      - "*.cloud.databricks.com:443"  # Databricks workspace
      - "*.zerobus.*.cloud.databricks.com:443"  # ZeroBus endpoint

    # Proxy support
    proxy:
      enabled: false
      http_proxy: "${HTTP_PROXY}"
      https_proxy: "${HTTPS_PROXY}"
      no_proxy: "localhost,127.0.0.1"

# Performance Tuning
performance:
  # Threading
  workers:
    reader_threads: 4  # Threads for reading from sources
    writer_threads: 2  # Threads for writing to ZeroBus

  # Connection pooling
  connection_pool:
    min_connections: 1
    max_connections: 10
    idle_timeout_seconds: 300

  # Memory limits
  memory:
    max_heap_mb: 2048
    gc_strategy: "G1GC"  # G1GC, ZGC, ShenandoahGC

# Deployment
deployment:
  mode: "production"  # development, staging, production
  instance_id: "${HOSTNAME}"  # Unique identifier for this instance

  # High availability
  ha:
    enabled: false
    role: "active"  # active, standby
    heartbeat_interval_seconds: 10
    failover_timeout_seconds: 30

  # Graceful shutdown
  shutdown:
    grace_period_seconds: 30
    drain_queue: true  # Wait for queue to drain before shutting down
    max_drain_time_seconds: 300

# Feature Flags
features:
  experimental_protocols: false
  advanced_filtering: true
  schema_evolution: true
  compression: true
